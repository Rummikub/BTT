{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Text into Features for Sentiment AnalysisÂ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, you will see how to create a classifier that performs sentiment analysis of a book review. \n",
    "You will learn how to use scikit-learn to convert raw text data (such as a book review) into a matrix of <i>term frequency-inverse document frequency</i> (TF-IDF) features, and how to train a logistic regression model using these transformed features. You will also experiment with using different document-frequency values and see how they affect the performance of a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages. Run the code cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import the scikit-learn `LogisticRegression`, the `train_test_split()` function for splitting the data into training and test sets, and the function `roc_auc_score` to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load a 'ready-to-fit' Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a data set containing book reviews taken from Amazon.com reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\dotto\\\\btt_course\\\\data\\\\bookReviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/555481064.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bookReviews.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\dotto\\\\btt_course\\\\data\\\\bookReviews.csv'"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(os.getcwd(), \"data\", \"bookReviews.csv\")\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/964094849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labeled Examples\n",
    "\n",
    "Let's create labeled examples from our dataset. We will have one text feature and one label. \n",
    "The code cell below carries out the following steps:\n",
    "\n",
    "* Gets the `Positive_Review` column from DataFrame `df` and assign it to the variable `y`. This will be our label. Note that the label contains True or False values that indicate whether a given book review is a positive one.\n",
    "* Gets the column `Review` from DataFrame `df` and assigns it to the variable `X`. This will be our feature. Note that the `Review` feature contains the book review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/1391717401.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Positive Review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "y = df['Positive Review'] \n",
    "X = df['Review']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/1716939484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at an example of a positive and a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/3412637916.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A Positive Review: \\n\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m67\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A Negative Review: \\n\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m85\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print('A Positive Review: \\n\\n', X[67])\n",
    "print('A Negative Review: \\n\\n', X[85])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Labeled Examples into Training and Test Sets\n",
    "\n",
    "Let's split our data into training and test sets with 75% of the data being the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/1511375040.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.75, random_state=1234)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Implement TF-IDF Vectorizer to Transform Text\n",
    "\n",
    "A popular technique when transforming text to numerical feature vectors is to use the TF-IDF statistical measure. TF-IDF calculates how relevant a word is in a document relative to a collection of documents. It weighs words to indicate the words that are the most unique to the document and therefore can be used to represent the characteristics of the document. For example, the word \"the\" appears in many documents and therefore is not characteristic of one particular document in a collection. On the other hand, if a word appears often in one document and rarely in other documents in the collection, the word is given a higher value of importance to that one document. \n",
    "Because TF-IDF provides an understanding of the context of the textual data, using TF-IDF features when performing classification for sentiment analysis yields more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a simple example. We will use the scikit-learn `TfidfVectorizer` class to implement a TF-IDF vectorizer. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). First, let's import `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the values in the TF-IDF matrix that `TfidfVectorizer` produces:\n",
    "\n",
    "* <b>Row</b>: each document will be represented by a numerical vector (row) in the matrix. \n",
    "* <b>Column</b>: each column represents one word in the vocabulary, i.e. the number of words in ALL of the documents in the collection (with the exclusion of words that appear too frequently or too infrequently; scikit-learn has a list of such words to ignore by default, but you will see later that you can specify frequency thresholds to eliminate words that appear too often/little). \n",
    "    * The value in the columns are the TF-IDF scores (weights) for the word in every document in the collection (one document per row)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below transforms two \"documents.\" Run the cell below to see what the code produces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 7: {'my': 5, 'cat': 1, 'loves': 4, 'yarn': 6, 'blue': 0, 'have': 3, 'dog': 2}\n",
      "\n",
      "Matrix:\n",
      "\n",
      "[[0.25969799 0.36499647 0.         0.         0.36499647 0.36499647\n",
      "  0.72999294]\n",
      " [0.44943642 0.         0.6316672  0.6316672  0.         0.\n",
      "  0.        ]]\n",
      "\n",
      "Heatmap of Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_collection = [\n",
    "    'My cat loves yarn. Blue yarn.',\n",
    "    'I have a blue dog.'\n",
    "]\n",
    "\n",
    "# 1. Create a TfidfVectorizer oject\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Fit the vectorizer to document_collection\n",
    "vectorizer.fit(document_collection)\n",
    "\n",
    "# 3. Print the vocabulary\n",
    "print(\"Vocabulary size {0}: {1}\\n\".format(len(vectorizer.vocabulary_), vectorizer.vocabulary_))\n",
    "\n",
    "# 4. Transform the data into numerical vectors \n",
    "print(\"Matrix:\\n\")\n",
    "resulting_matrix = vectorizer.transform(document_collection)\n",
    "\n",
    "# 5. Print the matrix\n",
    "print(resulting_matrix.todense())\n",
    "\n",
    "# 6. Visualize the matrix in a heatmap\n",
    "print(\"\\nHeatmap of Matrix:\\n\")\n",
    "df_print = pd.DataFrame(resulting_matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "plt.rcParams['figure.figsize'] = [6, 5]  \n",
    "ax = sns.heatmap(df_print, annot=True, cmap='coolwarm', cbar=False, yticklabels=[\"Document 1: My cat loves yarn. Blue yarn\", \"Document 2: I have a blue dog.\"]);\n",
    "_ =ax.set_title('TF-IDF Matrix');\n",
    "_ =ax.set_yticklabels(ax.get_yticklabels(), rotation = 0, fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the resulting matrix above:\n",
    "\n",
    "<table>\n",
    "    <tr><th></th><th>blue</th><th>cat</th><th>dog</th><th>have</th><th>loves</th><th>my</th><th>yarn</th></tr>\n",
    "<tr><th>Document 1</th><th>0.25969799</th><th>0.36499647</th><th>0.</th><th>0.</th><th>0.36499647</th><th>0.36499647</th><th>0.72999294</th><t/tr>\n",
    "<tr><th>Document 2</th><th>0.44943642</th><th>0.</th><th>0.6316672</th><th>0.6316672</th><th>0.</th><th>0.</th><th>0.</th></tr>   \n",
    "    </table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We have 7 words in our vocabulary: 'blue', 'cat', dog', 'have', 'loves', 'my, 'yarn'. Note that scikit-learn excluded the words 'I' and 'a'. Therefore, we have 7 columns. Note that each word is considered a feature. Therefore, in this example, we have seven features.\n",
    "\n",
    "The `vectorizer.vocabulary_` attribute outputs a mapping of words to column indices: {'my': 5, 'cat': 1, 'loves': 4, 'yarn': 6, 'blue': 0, 'have': 3, 'dog': 2}. This means that the TF-IDF score (weight) for the word 'my' is contained is in the 5th column (the first column is 0) in the matrix.\n",
    "\n",
    "The table above summarizes the results of the code. Note that in our first document, the word 'dog' does not appear. Therefore, its value in the document's vector is 0. Since the word 'blue' appears in both documents, its importance is not as high for either document. Therefore, its value in both document vectors is not very high compared to other values. However, since 'dog' appears in the second document only, it has a higher importance since it is characteristic of the second document; its value in that document's vector is 0.6316672. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now transform our book review textual features into numerical vectors using `TfidfVectorizer`. We will implement a TF-IDF transformation on the training and test data. Run the cell and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/1732313444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 2. Fit the vectorizer to X_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 3. Print the first 50 items in the vocabulary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Create a TfidfVectorizer oject\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Fit the vectorizer to X_train\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# 3. Print the first 50 items in the vocabulary\n",
    "print(\"Vocabulary size {0}: \".format(len(tfidf_vectorizer.vocabulary_)))\n",
    "print(str(list(tfidf_vectorizer.vocabulary_.items())[0:50])+'\\n')\n",
    "\n",
    "      \n",
    "# 4. Transform *both* the training and test data using the fitted vectorizer and its 'transform' attribute\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# 5. Print the matrix\n",
    "print(X_train_tfidf.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit a Logistic Regression Model to the Transformed Training Data and Evaluate the Model\n",
    "The code cell below trains a logistic regression model using the TF-IDF features and computes the AUC on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a LogisticRegression model object, and fit a Logistic Regression model to the transformed training data\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 2. Make predictions on the transformed test data using the predict_proba() method and \n",
    "# save the values of the second column\n",
    "probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "# 3. Make predictions on the transformed test data using the predict() method \n",
    "class_label_predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# 4. Compute the Area Under the ROC curve (AUC) for the test data. Note that this time we are using one \n",
    "# function 'roc_auc_score()' to compute the auc rather than using both 'roc_curve()' and 'auc()' as we have \n",
    "# done in the past\n",
    "auc = roc_auc_score(y_test, probability_predictions)\n",
    "print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "# 5. Print out the size of the resulting feature space using the 'vocabulary_' attribute of the vectorizer\n",
    "len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "\n",
    "# 6. Get a glimpse of the features:\n",
    "first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check two book reviews and see if our model properly predicted whether the reviews are good or bad reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Review #1:\\n')\n",
    "print(X_test.to_numpy()[124])\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(class_label_predictions[124])) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[124]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Review #2:\\n')\n",
    "print(X_test.to_numpy()[238])\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(class_label_predictions[238])) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[238]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Experiment with Different Document Frequency Values and Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a `TfidfVectorizer` object, you can use the parameter `min_df` to specify the minimum 'document frequency.' This allows you to ignore words that have a document frequency lower than the specified value. In other words, they ignore words that occur in too few documents.\n",
    "\n",
    "The code cell below puts the code above into a loop over a range of 'document frequency' values. For each value, it fits a vectorizer specifying `ngram_range=(1,2)` (instead of the default (1,1)). Run the code and inspect the results. \n",
    "\n",
    "Note: This may take a short while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for min_df in [1,10,100,1000]:\n",
    "    \n",
    "    print('\\nMin Document Frequency Value: {0}'.format(min_df))\n",
    "    \n",
    "    # 1. Create a TfidfVectorizer oject\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df, ngram_range=(1,2))\n",
    "\n",
    "    # 2. Fit the vectorizer to X_train\n",
    "    tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "    # 3. Transform the training and test data\n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    # 4. Create a LogisticRegression model object, and fit a Logistic Regression model to the transformed \n",
    "    # training data\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # 5. Make predictions on the transformed test data using the predict_proba() method and save \n",
    "    # the values of the second column\n",
    "    probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "    # 6. Compute the Area Under the ROC curve (AUC) for the test data.\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "    # 7. Compute the size of the resulting feature space using the 'vocabulary_' attribute of the vectorizer\n",
    "    len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "    print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "    \n",
    "    # 8. Get a glimpse of the features:\n",
    "    first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "    print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n",
    "\n",
    "    # 9: Print the first five \"stop words\" - words that we are ignoring\n",
    "    first_five_stop = list(tfidf_vectorizer.stop_words_)[1:5]\n",
    "    print('Glimpse of first 5 stop words \\n{}:'.format(first_five_stop))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis:</b> Just as you can use the parameter `min_df` to specify the minimum 'document frequency,' you can use the parameter `max_df` to ignore words that have a document frequency higher than the specified value. Try using the parameter `max_def` and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_df in [1,10,100,1000]:\n",
    "    \n",
    "    print('\\nMax Document Frequency Value: {0}'.format(max_df))\n",
    "    \n",
    "    # 1. Create a TfidfVectorizer oject\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=max_df, ngram_range=(1,2))\n",
    "\n",
    "    # 2. Fit the vectorizer to X_train\n",
    "    tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "    # 3. Transform the training and test data\n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    # 4. Create a LogisticRegression model object, and fit a Logistic Regression model to the transformed \n",
    "    # training data\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # 5. Make predictions on the transformed test data using the predict_proba() method and save \n",
    "    # the values of the second column\n",
    "    probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "    # 6. Compute the Area Under the ROC curve (AUC) for the test data.\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "    # 7. Compute the size of the resulting feature space using the 'vocabulary_' attribute of the vectorizer\n",
    "    len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "    print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "    \n",
    "    # 8. Get a glimpse of the features:\n",
    "    first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "    print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n",
    "\n",
    "    # 9: Print the first five \"stop words\" - words that we are ignoring\n",
    "    first_five_stop = list(tfidf_vectorizer.stop_words_)[1:5]\n",
    "    print('Glimpse of first 5 stop words \\n{}:'.format(first_five_stop))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
